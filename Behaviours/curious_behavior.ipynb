{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curious Behavior Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Create display widgets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipywidgets'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mipywidgets\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwidgets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwidgets\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'ipywidgets'"
     ]
    }
   ],
   "source": [
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "import cv2\n",
    "\n",
    "# Create widgets for displaying images\n",
    "display_color = widgets.Image(format='jpeg', width='30%')\n",
    "display_depth = widgets.Image(format='jpeg', width='30%')\n",
    "layout = widgets.Layout(width='100%')\n",
    "\n",
    "sidebyside = widgets.HBox([display_color, display_depth], layout=layout)\n",
    "display(sidebyside)\n",
    "\n",
    "# Convert numpy array to jpeg coded data for displaying\n",
    "def bgr8_to_jpeg(value):\n",
    "    return bytes(cv2.imencode('.jpg', value)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Initialize camera and implement curious behavior**\n",
    "\n",
    "The robot will exhibit curious behavior through three states:\n",
    "- **Scanning**: Rotating to search for objects when none detected\n",
    "- **Approaching**: Moving toward detected objects\n",
    "- **Investigating**: Circling around objects at close range\n",
    "\n",
    "After investigation, the robot returns to scanning mode to explore more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyzed.sl as sl\n",
    "import threading\n",
    "import motors\n",
    "\n",
    "# Initialize the Robot class\n",
    "robot = motors.MotorsYukon(mecanum=False)\n",
    "\n",
    "class Camera():\n",
    "    def __init__(self):\n",
    "        super(Camera, self).__init__()\n",
    "\n",
    "        self.zed = sl.Camera()\n",
    "        # Create a InitParameters object and set configuration parameters\n",
    "        init_params = sl.InitParameters()\n",
    "        init_params.camera_resolution = sl.RESOLUTION.VGA\n",
    "        init_params.depth_mode = sl.DEPTH_MODE.ULTRA\n",
    "        init_params.coordinate_units = sl.UNIT.MILLIMETER\n",
    "\n",
    "        # Open the camera\n",
    "        status = self.zed.open(init_params)\n",
    "        if status != sl.ERROR_CODE.SUCCESS:\n",
    "            print(\"Camera Open : \"+repr(status)+\". Exit program.\")\n",
    "            self.zed.close()\n",
    "            exit(1)\n",
    "\n",
    "        # Create and set RuntimeParameters after opening the camera\n",
    "        self.runtime = sl.RuntimeParameters()\n",
    "\n",
    "        # Flag to control the thread\n",
    "        self.thread_runnning_flag = False\n",
    "\n",
    "        # Get the height and width\n",
    "        camera_info = self.zed.get_camera_information()\n",
    "        self.width = camera_info.camera_configuration.resolution.width\n",
    "        self.height = camera_info.camera_configuration.resolution.height\n",
    "        self.image = sl.Mat(self.width, self.height, sl.MAT_TYPE.U8_C4, sl.MEM.CPU)\n",
    "        self.depth = sl.Mat(self.width, self.height, sl.MAT_TYPE.F32_C1, sl.MEM.CPU)\n",
    "        self.point_cloud = sl.Mat(self.width, self.height, sl.MAT_TYPE.F32_C4, sl.MEM.CPU)\n",
    "        \n",
    "        # Curiosity state variables\n",
    "        self.curiosity_state = 'scanning'\n",
    "        self.investigation_counter = 0\n",
    "\n",
    "    def _capture_frames(self):\n",
    "        while(self.thread_runnning_flag == True):\n",
    "            if self.zed.grab(self.runtime) == sl.ERROR_CODE.SUCCESS:\n",
    "                \n",
    "                # Retrieve Left image\n",
    "                self.zed.retrieve_image(self.image, sl.VIEW.LEFT)\n",
    "                # Retrieve depth map. Depth is aligned on the left image\n",
    "                self.zed.retrieve_measure(self.depth, sl.MEASURE.DEPTH)\n",
    "    \n",
    "                self.color_value = self.image.get_data()\n",
    "                # Scale for real-time data displaying\n",
    "                scale = 0.1\n",
    "                resized_image = cv2.resize(self.color_value, None, fx=scale, fy=scale, \n",
    "                                          interpolation=cv2.INTER_AREA)\n",
    "                cv2.circle(resized_image, (int(self.width*scale//2), int(self.height*scale//2)), \n",
    "                          1, (0, 255, 0))\n",
    "                display_color.value = bgr8_to_jpeg(resized_image)\n",
    "                \n",
    "                self.depth_image = np.asanyarray(self.depth.get_data())\n",
    "\n",
    "                # Process depth image for curious behavior\n",
    "                depth_image_test = self.depth_image.copy()\n",
    "                depth_image_test = np.nan_to_num(depth_image_test, nan=0.0).astype(np.float32)\n",
    "                \n",
    "                depth_image_test[:94, :] = 0\n",
    "                depth_image_test[282:, :] = 0\n",
    "                depth_image_test[:, :168] = 0\n",
    "                depth_image_test[:, 504:] = 0\n",
    "\n",
    "                # Filter depth values\n",
    "                depth_image_test[depth_image_test < 100] = 0\n",
    "                depth_image_test[depth_image_test > 2000] = 0\n",
    "                \n",
    "                depth_colormap = cv2.applyColorMap(\n",
    "                    cv2.convertScaleAbs(depth_image_test, alpha=0.03), \n",
    "                    cv2.COLORMAP_JET)\n",
    "                \n",
    "                # CURIOUS BEHAVIOR - three-state exploration\n",
    "                if self.curiosity_state == 'scanning':\n",
    "                    if depth_image_test.max() == 0:\n",
    "                        # No object detected - keep searching\n",
    "                        robot.spinRight(0.3)\n",
    "                        cv2.putText(depth_colormap, 'SCANNING', (260, 188), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2, cv2.LINE_AA)\n",
    "                        print('Curious: Scanning for objects', end='\\r')\n",
    "                    else:\n",
    "                        # Object found - switch to approach\n",
    "                        self.curiosity_state = 'approach'\n",
    "                        \n",
    "                elif self.curiosity_state == 'approach':\n",
    "                    if depth_image_test.max() == 0:\n",
    "                        # Lost object - return to scanning\n",
    "                        self.curiosity_state = 'scanning'\n",
    "                    else:\n",
    "                        distance = depth_image_test[depth_image_test != 0].min()\n",
    "                        \n",
    "                        if distance > 700:\n",
    "                            # Move toward object\n",
    "                            robot.forward(0.4)\n",
    "                            cv2.putText(depth_colormap, f'APPROACH {distance:.0f}mm', (220, 188),\n",
    "                                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 165, 0), 2, cv2.LINE_AA)\n",
    "                            print(f'Curious: Approaching {distance:.0f}mm', end='\\r')\n",
    "                        else:\n",
    "                            # Close enough - start investigation\n",
    "                            self.curiosity_state = 'investigate'\n",
    "                            self.investigation_counter = 0\n",
    "                            \n",
    "                elif self.curiosity_state == 'investigate':\n",
    "                    # Circle around object\n",
    "                    robot.spinRight(0.4)\n",
    "                    self.investigation_counter += 1\n",
    "                    cv2.putText(depth_colormap, f'INVESTIGATE {self.investigation_counter}/60', (200, 188),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (147, 20, 255), 2, cv2.LINE_AA)\n",
    "                    print(f'Curious: Investigating ({self.investigation_counter}/60)', end='\\r')\n",
    "                    \n",
    "                    if self.investigation_counter > 60:\n",
    "                        # Finished investigation - return to scanning\n",
    "                        self.curiosity_state = 'scanning'\n",
    "                    \n",
    "                resized_depth_colormap = cv2.resize(depth_colormap, None, fx=scale, fy=scale,\n",
    "                                                    interpolation=cv2.INTER_AREA)\n",
    "                display_depth.value = bgr8_to_jpeg(resized_depth_colormap)\n",
    "                \n",
    "    def start(self):\n",
    "        if self.thread_runnning_flag == False:\n",
    "            self.thread_runnning_flag = True\n",
    "            self.thread = threading.Thread(target=self._capture_frames)\n",
    "            self.thread.start()\n",
    "\n",
    "    def stop(self):\n",
    "        if self.thread_runnning_flag == True:\n",
    "            self.thread_runnning_flag = False\n",
    "            self.thread.join()\n",
    "            robot.stop()\n",
    "\n",
    "camera = Camera()\n",
    "camera.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To stop the camera and robot:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The curious behavior demonstrates active exploration through three distinct states:\n",
    "\n",
    "1. **Scanning State**: Robot rotates slowly (spinRight at 0.3 speed) searching for objects in the environment\n",
    "2. **Approach State**: When object detected, robot moves forward (0.4 speed) until reaching ~700mm distance\n",
    "3. **Investigate State**: Robot circles around object (spinRight at 0.4 speed) for 60 frames to examine it from multiple angles\n",
    "\n",
    "After investigation completes, the robot returns to scanning state to continue exploring. If an object is lost during approach, the robot immediately returns to scanning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
