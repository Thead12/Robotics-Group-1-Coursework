{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc4e8eb8",
   "metadata": {},
   "source": [
    "# Aggression Behavior Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0f6c4a",
   "metadata": {},
   "source": [
    "**Step 1: Create display widgets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9d2a3a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mipywidgets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwidgets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwidgets\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Create widgets for displaying images\u001b[39;00m\n\u001b[0;32m      6\u001b[0m display_color \u001b[38;5;241m=\u001b[39m widgets\u001b[38;5;241m.\u001b[39mImage(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjpeg\u001b[39m\u001b[38;5;124m'\u001b[39m, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m30\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "import cv2\n",
    "\n",
    "# Create widgets for displaying images\n",
    "display_color = widgets.Image(format='jpeg', width='30%')\n",
    "display_depth = widgets.Image(format='jpeg', width='30%')\n",
    "layout = widgets.Layout(width='100%')\n",
    "\n",
    "sidebyside = widgets.HBox([display_color, display_depth], layout=layout)\n",
    "display(sidebyside)\n",
    "\n",
    "# Convert numpy array to jpeg coded data for displaying\n",
    "def bgr8_to_jpeg(value):\n",
    "    return bytes(cv2.imencode('.jpg', value)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8da20ea",
   "metadata": {},
   "source": [
    "**Step 2: Initialize camera and implement aggression behavior**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de70962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyzed.sl as sl\n",
    "import threading\n",
    "import motors\n",
    "\n",
    "# Initialize the Robot class\n",
    "robot = motors.MotorsYukon(mecanum=False)\n",
    "\n",
    "class Camera():\n",
    "    def __init__(self):\n",
    "        super(Camera, self).__init__()\n",
    "\n",
    "        self.zed = sl.Camera()\n",
    "        # Create a InitParameters object and set configuration parameters\n",
    "        init_params = sl.InitParameters()\n",
    "        init_params.camera_resolution = sl.RESOLUTION.VGA\n",
    "        init_params.depth_mode = sl.DEPTH_MODE.ULTRA\n",
    "        init_params.coordinate_units = sl.UNIT.MILLIMETER\n",
    "\n",
    "        # Open the camera\n",
    "        status = self.zed.open(init_params)\n",
    "        if status != sl.ERROR_CODE.SUCCESS:\n",
    "            print(\"Camera Open : \"+repr(status)+\". Exit program.\")\n",
    "            self.zed.close()\n",
    "            exit(1)\n",
    "\n",
    "        # Create and set RuntimeParameters after opening the camera\n",
    "        self.runtime = sl.RuntimeParameters()\n",
    "\n",
    "        # Flag to control the thread\n",
    "        self.thread_runnning_flag = False\n",
    "\n",
    "        # Get the height and width\n",
    "        camera_info = self.zed.get_camera_information()\n",
    "        self.width = camera_info.camera_configuration.resolution.width\n",
    "        self.height = camera_info.camera_configuration.resolution.height\n",
    "        self.image = sl.Mat(self.width, self.height, sl.MAT_TYPE.U8_C4, sl.MEM.CPU)\n",
    "        self.depth = sl.Mat(self.width, self.height, sl.MAT_TYPE.F32_C1, sl.MEM.CPU)\n",
    "        self.point_cloud = sl.Mat(self.width, self.height, sl.MAT_TYPE.F32_C4, sl.MEM.CPU)\n",
    "\n",
    "        self.aggression = 'checking for target'\n",
    "        self.target = 0\n",
    "\n",
    "    def _capture_frames(self):\n",
    "        while(self.thread_runnning_flag == True):\n",
    "            if self.zed.grab(self.runtime) == sl.ERROR_CODE.SUCCESS:\n",
    "                \n",
    "                # Retrieve Left image\n",
    "                self.zed.retrieve_image(self.image, sl.VIEW.LEFT)\n",
    "                # Retrieve depth map. Depth is aligned on the left image\n",
    "                self.zed.retrieve_measure(self.depth, sl.MEASURE.DEPTH)\n",
    "    \n",
    "                self.color_value = self.image.get_data()\n",
    "                # Scale for real-time data displaying\n",
    "                scale = 0.1\n",
    "                resized_image = cv2.resize(self.color_value, None, fx=scale, fy=scale, \n",
    "                                          interpolation=cv2.INTER_AREA)\n",
    "                cv2.circle(resized_image, (int(self.width*scale//2), int(self.height*scale//2)), \n",
    "                          1, (0, 255, 0))\n",
    "                display_color.value = bgr8_to_jpeg(resized_image)\n",
    "                \n",
    "                self.depth_image = np.asanyarray(self.depth.get_data())\n",
    "\n",
    "                # Process depth image for aggression behavior\n",
    "                depth_image_test = self.depth_image.copy()\n",
    "                depth_image_test = np.nan_to_num(depth_image_test, nan=0.0).astype(np.float32)\n",
    "                \n",
    "                # Define central area (similar to Tutorial 3 Part B)\n",
    "                depth_image_test[:94, :] = 0\n",
    "                depth_image_test[282:, :] = 0\n",
    "                depth_image_test[:, :168] = 0\n",
    "                depth_image_test[:, 504:] = 0\n",
    "\n",
    "                # Filter depth values\n",
    "                depth_image_test[depth_image_test < 100] = 0\n",
    "                depth_image_test[depth_image_test > 2000] = 0\n",
    "                \n",
    "                depth_colormap = cv2.applyColorMap(\n",
    "                    cv2.convertScaleAbs(depth_image_test, alpha=0.03), \n",
    "                    cv2.COLORMAP_JET)\n",
    "        \n",
    "                # aggression behaviour \n",
    "                if self.aggression == 'checking for target':\n",
    "                    if depth_image_test.max() == 0:\n",
    "                        # target no found -- keep checking for target\n",
    "                        robot.spinRight(0.3)\n",
    "                        cv2.putText(depth_colormap, 'checking for target', (260, 188), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2, cv2.LINE_AA)\n",
    "                        print('Aggression: Checking for target', end='\\r')\n",
    "                    else:\n",
    "                        # target found -- Get ready to attack\n",
    "                        self.aggression = 'target found'\n",
    "                \n",
    "                elif self.aggression == \"target found\":\n",
    "                    # bull mode activated - this will attack\n",
    "                    cv2.putText(depth_colormap, f'Attack', (220, 188),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 165, 0), 2, cv2.LINE_AA)\n",
    "                    print(f'Aggression: Attack', end='\\r')\n",
    "                    self.aggression = 'attack'\n",
    "                \n",
    "                elif self.aggression == 'attack':\n",
    "                    if depth_image_test.max() == 0:\n",
    "                        # can't find target -- searching for target\n",
    "                        robot.stop() #\n",
    "                        self.aggression = 'checking for target'\n",
    "                        self.target +=1\n",
    "                    else:\n",
    "                        distance = depth_image_test[depth_image_test !=0].min()\n",
    "\n",
    "                        if distance > 1000: \n",
    "                            # far normal speed\n",
    "                            speed = 0.4\n",
    "                            color = (255, 165, 0)  #orange\n",
    "                            intensity = \"chasing\"\n",
    "                        elif distance > 600:\n",
    "                            # closer - more intense\n",
    "                            speed = 0.6\n",
    "                            intensity = \"rushing\"\n",
    "                            color = (255, 69, 0) # red orange\n",
    "                        elif distance > 300:\n",
    "                            # closer - more intense\n",
    "                            speed = 0.8\n",
    "                            intensity = \"engage attack\"\n",
    "                            color = (255, 0, 0) # red\n",
    "                        else:\n",
    "                            # close keep pushing\n",
    "                            speed = 1.0\n",
    "                            intensity = \"destory\"\n",
    "                            color = (139, 0, 0) # dark-red\n",
    "                        # keep attacking\n",
    "                        robot.forward(speed)\n",
    "                        cv2.putText(depth_colormap, f'{intensity} {distance:.0f}mm', (220, 188), cv2.FONT_HERSHEY_SIMPLEX, 0.6,  color, 2, cv2.LINE_AA)\n",
    "                        print(f'Aggression: {intensity} {distance:.0f}mm', end='\\r')\n",
    "                        \n",
    "                resized_depth_colormap = cv2.resize(depth_colormap, None, fx=scale, fy=scale,\n",
    "                                                    interpolation=cv2.INTER_AREA)\n",
    "                display_depth.value = bgr8_to_jpeg(resized_depth_colormap)            \n",
    "\n",
    "    \n",
    "    def start(self):\n",
    "        if self.thread_runnning_flag == False:\n",
    "            self.thread_runnning_flag = True\n",
    "            self.thread = threading.Thread(target=self._capture_frames)\n",
    "            self.thread.start()\n",
    "\n",
    "    def stop(self):\n",
    "        if self.thread_runnning_flag == True:\n",
    "            self.thread_runnning_flag = False\n",
    "            self.thread.join()\n",
    "            robot.stop()\n",
    "\n",
    "camera = Camera()\n",
    "camera.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52784ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# improvevd\n",
    "\n",
    "import time\n",
    "dog_movement = { 'active':False, \n",
    "                'rush': 0, \n",
    "                'charging':None, \n",
    "                'barking':0} # similar why a dog barks at people and tire to attack\n",
    "\n",
    "def aggressive_behavior(frame, depth_colormap, human_detected, distance, bbox):\n",
    "    \"\"\"Aggressive behavior - relentlessly push toward humans without stopping\"\"\"\n",
    "    global dog_movement\n",
    "\n",
    "    if human_detected and distance != float('inf'):\n",
    "        # Draw orange box\n",
    "        cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), \n",
    "                     (int(bbox[2]), int(bbox[3])), (0, 165, 255), 2)\n",
    "        \n",
    "        bbox_center_x = (bbox[0] + bbox[2]) / 2\n",
    "        frame_center_x = camera.width / 2\n",
    "\n",
    "        # dog movement logic\n",
    "        if 250 < distance <= 400:\n",
    "            if not dog_movement['active']:\n",
    "                dog_movement['active'] = True\n",
    "                dog_movement['barking'] = 0\n",
    "                dog_movement['charging'] = 'forward'\n",
    "                dog_movement['rush'] = time.time()\n",
    "\n",
    "                # 3 to laps of attacking\n",
    "            if dog_movement['barking'] < 3:\n",
    "                current_time = time.time()\n",
    "                stopped = current_time - dog_movement['rush']\n",
    "\n",
    "                    #go to attack forward like warning in a way\n",
    "                if dog_movement['charging'] == 'forward':\n",
    "                    if stopped < 0.5:\n",
    "                        robot.forward(0.8)\n",
    "                        cv2.putText(depth_colormap, \n",
    "                                        f'dog or bull: action {dog_movement[\"barking\"]+1}/3 - {distance:.0f}mm',\n",
    "                                        (80, 188), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 2)\n",
    "                        print(f'dog or bull : forward movement {dog_movement[\"barking\"]+1}/3', end='\\r')\n",
    "                    else: # will be go backward\n",
    "                        dog_movement['charging'] = 'backward'\n",
    "                        dog_movement['rush'] = current_time\n",
    "                    #go back breiftly\n",
    "                elif dog_movement['charging'] == 'backward':\n",
    "                    if stopped < 0.5:\n",
    "                            robot.backward(0.8)\n",
    "                            cv2.putText(depth_colormap, \n",
    "                                        f'dog or bull: go back {dog_movement[\"barking\"]+1}/3 - {distance:.0f}mm',\n",
    "                                        (80, 188), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 2)\n",
    "                            print(f'dog or bull : back {dog_movement[\"barking\"]+1}/3', end='\\r')\n",
    "                    else: # one cycle\n",
    "                            dog_movement['barking']  += 1\n",
    "                            dog_movement['charging'] = 'forward'\n",
    "                            dog_movement['rush'] = current_time\n",
    "\n",
    "                return\n",
    "                \n",
    "            else: # finsh the 3 cycle\n",
    "                    dog_movement['active'] = False   \n",
    "\n",
    "        if distance > 400 or distance <= 250:\n",
    "            dog_movement['active'] = False\n",
    "            dog_movement['barking'] = 0\n",
    "\n",
    "        # Determine speed based on distance - faster when farther\n",
    "        if distance > 1000:\n",
    "            speed = 0.4\n",
    "            intensity = \"chasing\"\n",
    "            color = (255, 165, 0)  # orange\n",
    "        elif distance > 600:\n",
    "            speed = 0.6\n",
    "            intensity = \"chasing\"\n",
    "            color = (255, 69, 0)  # red-orange\n",
    "        elif distance > 400:\n",
    "            speed = 0.8\n",
    "            intensity = \"engage attack\"\n",
    "            color = (255, 0, 0)  # red\n",
    "        elif distance > 250:\n",
    "            speed = 0.7\n",
    "            intensity = \"attack\"\n",
    "            color = (255, 0, 0)  # red\n",
    "        else:\n",
    "            # Close range - KEEP PUSHING at maximum speed\n",
    "            speed = 1.0\n",
    "            intensity = \"destroy\"\n",
    "            color = (139, 0, 0)  # dark-red\n",
    "        \n",
    "        \n",
    "        # Always move forward or turn toward human - NEVER STOP\n",
    "        if bbox_center_x < frame_center_x - 50:\n",
    "            robot.left(0.5)\n",
    "            cv2.putText(depth_colormap, f'AGGRESSIVE: {intensity} LEFT {distance:.0f}mm', \n",
    "                       (100, 188), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        elif bbox_center_x > frame_center_x + 50:\n",
    "            robot.right(0.5)\n",
    "            cv2.putText(depth_colormap, f'AGGRESSIVE: {intensity} RIGHT {distance:.0f}mm', \n",
    "                       (100, 188), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        else:\n",
    "            robot.forward(speed)\n",
    "            cv2.putText(depth_colormap, f'AGGRESSIVE: {intensity} {distance:.0f}mm!', \n",
    "                       (120, 188), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        \n",
    "        print(f'Aggression: {intensity} {distance:.0f}mm (speed: {speed})', end='\\r')\n",
    "    else:\n",
    "\n",
    "        dog_movement['active'] = False\n",
    "        dog_movement['barking'] = 0\n",
    "        # No human detected - spin to search\n",
    "        robot.spinRight(0.3)\n",
    "        cv2.putText(depth_colormap, 'AGGRESSIVE: Searching for target...', \n",
    "                   (130, 188), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "        print('Aggression: Checking for target', end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
