{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271da67678aa47089eb13ecbaebd0cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'', format='jpeg', width='45%'), Image(value=b'', format='jpeg', width='45%')), la…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "import cv2\n",
    "import motors\n",
    "\n",
    "# Create widgets for displaying images\n",
    "display_color = widgets.Image(format='jpeg', width='45%')\n",
    "display_depth = widgets.Image(format='jpeg', width='45%')\n",
    "layout = widgets.Layout(width='100%')\n",
    "\n",
    "sidebyside = widgets.HBox([display_color, display_depth], layout=layout)\n",
    "display(sidebyside)\n",
    "\n",
    "# Convert numpy array to jpeg coded data for displaying\n",
    "def bgr8_to_jpeg(value):\n",
    "    return bytes(cv2.imencode('.jpg', value)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# full model\n",
    "model = YOLO(\"yolo11l_half.engine\")\n",
    "\n",
    "# human only model\n",
    "# model = YOLO('best.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistogramPersonIdentifier:\n",
    "    \"\"\"\n",
    "    Simple HSV-histogram-based person re-identification.\n",
    "    Keeps an in-memory DB of person_id -> histogram.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, similarity_thresh=0.6, h_bins=16, s_bins=16):\n",
    "        self.person_db = {}   # person_id -> hist\n",
    "        self.next_id = 0\n",
    "        self.similarity_thresh = similarity_thresh\n",
    "        self.h_bins = h_bins\n",
    "        self.s_bins = s_bins\n",
    "\n",
    "    def _get_histogram(self, roi_bgr):\n",
    "        \"\"\"Compute normalised HSV histogram for a ROI.\"\"\"\n",
    "        hsv = cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2HSV)\n",
    "        hist = cv2.calcHist(\n",
    "            [hsv], [0, 1], None,\n",
    "            [self.h_bins, self.s_bins],\n",
    "            [0, 180, 0, 256]\n",
    "        )\n",
    "        cv2.normalize(hist, hist, 0, 1, cv2.NORM_MINMAX)\n",
    "        return hist\n",
    "\n",
    "    def _match_person(self, hist):\n",
    "        \"\"\"Return best-matching person ID or None.\"\"\"\n",
    "        best_id = None\n",
    "        best_score = -1\n",
    "\n",
    "        for pid, ref_hist in self.person_db.items():\n",
    "            score = cv2.compareHist(ref_hist, hist, cv2.HISTCMP_CORREL)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_id = pid\n",
    "\n",
    "        if best_score > self.similarity_thresh:\n",
    "            return best_id\n",
    "        return None\n",
    "\n",
    "    def assign_ids(self, frame, detections):\n",
    "        \"\"\"\n",
    "        For each person box, assign a stable ID based on histogram.\n",
    "        Returns list of (x1, y1, x2, y2, person_id).\n",
    "        \"\"\"\n",
    "        results = []\n",
    "\n",
    "        for box in detections.boxes:\n",
    "            cls = int(box.cls[0])\n",
    "            if cls != 0:\n",
    "                continue  # only PERSON class\n",
    "\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            roi = frame[y1:y2, x1:x2]\n",
    "\n",
    "            if roi.size == 0:\n",
    "                continue\n",
    "\n",
    "            hist = self._get_histogram(roi)\n",
    "            pid = self._match_person(hist)\n",
    "\n",
    "            # New identity if no good match\n",
    "            if pid is None:\n",
    "                pid = self.next_id\n",
    "                self.person_db[pid] = hist\n",
    "                self.next_id += 1\n",
    "\n",
    "            results.append((x1, y1, x2, y2, pid))\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "identifier = HistogramPersonIdentifier(similarity_thresh=0.6)\n",
    "\n",
    "def detect_human_from_results(results, color_frame, depth_frame, width, height):\n",
    "    global identifier\n",
    "    \n",
    "    min_distance = float('inf')\n",
    "    best_bbox = None\n",
    "    best_center = None\n",
    "\n",
    "    # for result in results:\n",
    "    #     for i, bbox in enumerate(result.boxes.xyxy):\n",
    "    #         cx = int((bbox[0] + bbox[2]) / 2)\n",
    "    #         cy = int((bbox[1] + bbox[3]) / 2)\n",
    "\n",
    "    #         # Depth lookup bounds check\n",
    "    #         if 0 <= cx < width and 0 <= cy < height:\n",
    "    #             distance = depth_frame[cy, cx]\n",
    "\n",
    "    #             if not np.isnan(distance) and distance > 0:\n",
    "    #                 if distance < min_distance:\n",
    "    #                     min_distance = distance\n",
    "    #                     best_bbox = bbox\n",
    "    #                     best_center = [cx, cy]\n",
    "\n",
    "    tracks = identifier.assign_ids(frame, yolo_result)\n",
    "\n",
    "    x1, y1, x2, y2, pid = tracks[0]\n",
    "    \n",
    "    cx = int((x1 + x2) / 2)\n",
    "    cy = int((y1 + y2) / 2)\n",
    "\n",
    "    best_bbox = [x1, x2, y1, y2]\n",
    "    best_center = [cx, cy]\n",
    "\n",
    "    return best_bbox is not None, min_distance, best_bbox, best_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_to_angle(found, center, width, height, hfov, vfov):\n",
    "\n",
    "    if not found:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    px = center[0]\n",
    "    py = center[1]\n",
    "\n",
    "    cx, cy = width / 2, height / 2\n",
    "\n",
    "    h_angle = ((px - cx) / cx) * (hfov / 2)\n",
    "    v_angle = ((py - cy) / cy) * (vfov / 2)\n",
    "\n",
    "    return h_angle, v_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-21 10:50:36 UTC][ZED][INFO] Logging level INFO\n",
      "[2025-11-21 10:50:36 UTC][ZED][INFO] Logging level INFO\n",
      "[2025-11-21 10:50:36 UTC][ZED][INFO] Logging level INFO\n",
      "[2025-11-21 10:50:37 UTC][ZED][INFO] [Init]  Depth mode: ULTRA\n",
      "[2025-11-21 10:50:38 UTC][ZED][INFO] [Init]  Camera successfully opened.\n",
      "[2025-11-21 10:50:38 UTC][ZED][INFO] [Init]  Camera FW version: 1523\n",
      "[2025-11-21 10:50:38 UTC][ZED][INFO] [Init]  Video mode: VGA@100\n",
      "[2025-11-21 10:50:38 UTC][ZED][INFO] [Init]  Serial Number: S/N 35129214\n"
     ]
    }
   ],
   "source": [
    "from camera import Camera \n",
    "from springfollower import SpringFollower\n",
    "\n",
    "#create a camera object\n",
    "cam = Camera()\n",
    "cam.start() # start capturing the data\n",
    "\n",
    "#create follower\n",
    "follower = SpringFollower(speed=0.0, follow_distance=5.0, stopping_distance=2.0, v_max = 0.5, deadband=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We YOLO\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "HUman detected\n",
      "Full model inference on  range(0, 100)  frames completed.\n",
      "Elapsed Time: 7.562766790390015 seconds\n",
      "Control frequency =  13.222674025473019\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "\n",
    "display_camera = True\n",
    "\n",
    "run_time = range(100)\n",
    "start_time = time.time()\n",
    "yolo_interval = 100\n",
    "\n",
    "\n",
    "latest_color_frame = None\n",
    "latest_depth_frame = None\n",
    "\n",
    "latest_results = None\n",
    "\n",
    "# =========== Main Loop ===========\n",
    "for i in run_time:\n",
    "    # get current frame\n",
    "    latest_color_frame, latest_depth_frame = cam.get_frame()\n",
    "\n",
    "    # prin(\"\n",
    "    # detect humans\n",
    "    if i % yolo_interval == 0:\n",
    "        print(\"We YOLO\")\n",
    "        # Confidence threshold to filter out noise.\n",
    "        latest_results = model(latest_color_frame, classes=[0], verbose=False, conf=0.5)\n",
    "        \n",
    "    found, dist, bbox, center = detect_human_from_results(\n",
    "        latest_results, latest_color_frame, latest_depth_frame, cam.width, cam.height\n",
    "        )\n",
    "    \n",
    "    # calculate angle deviation from center\n",
    "    h_angle, v_angle = pixel_to_angle(\n",
    "        found, center, cam.width, cam.height, cam.hfov, cam.vfov\n",
    "    )\n",
    "\n",
    "    #print(h_angle)\n",
    "    follower.update(found, h_angle, dist)\n",
    "\n",
    "    # =========== Display images ===========\n",
    "    \n",
    "    if display_camera:\n",
    "        # Prepare depth colormap for display\n",
    "        depth_colormap = cv2.applyColorMap(\n",
    "            cv2.convertScaleAbs(latest_depth_frame, alpha=0.03), \n",
    "            cv2.COLORMAP_JET)\n",
    "        scale = 0.1\n",
    "        resized_color = cv2.resize(latest_color_frame, None, fx=scale, fy=scale, \n",
    "                                   interpolation=cv2.INTER_AREA)\n",
    "        resized_depth = cv2.resize(depth_colormap, None, fx=scale, fy=scale, \n",
    "                                   interpolation=cv2.INTER_AREA)\n",
    "        display_color.value = bgr8_to_jpeg(resized_color)\n",
    "        display_depth.value = bgr8_to_jpeg(resized_depth)\n",
    "\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Full model inference on \", run_time,\" frames completed.\")\n",
    "print(f\"Elapsed Time: {elapsed_time} seconds\")\n",
    "\n",
    "control_frequency = len(run_time)/elapsed_time\n",
    "print(f\"Control frequency = \", control_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "follower.stop()\n",
    "cam.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
