{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597c8bce00bd4cc5914c53f24745afc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'', format='jpeg', width='45%'), Image(value=b'', format='jpeg', width='45%')), la…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "import cv2\n",
    "import motors\n",
    "\n",
    "# Create widgets for displaying images\n",
    "display_color = widgets.Image(format='jpeg', width='45%')\n",
    "display_depth = widgets.Image(format='jpeg', width='45%')\n",
    "layout = widgets.Layout(width='100%')\n",
    "\n",
    "sidebyside = widgets.HBox([display_color, display_depth], layout=layout)\n",
    "display(sidebyside)\n",
    "\n",
    "# Convert numpy array to jpeg coded data for displaying\n",
    "def bgr8_to_jpeg(value):\n",
    "    return bytes(cv2.imencode('.jpg', value)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# full model\n",
    "#model = YOLO(\"yolo11l_half.engine\")\n",
    "\n",
    "model = YOLO(\"yolo11l_half.engine\")\n",
    "\n",
    "\n",
    "# human only model\n",
    "# model = YOLO('best.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def detect_human_from_results(results, depth_frame, width, height):\n",
    "    min_distance = float('inf')\n",
    "    best_bbox = None\n",
    "    best_center = None\n",
    "\n",
    "    for result in results:\n",
    "        for i, bbox in enumerate(result.boxes.xyxy):\n",
    "            cx = int((bbox[0] + bbox[2]) / 2)\n",
    "            cy = int((bbox[1] + bbox[3]) / 2)\n",
    "\n",
    "            # Depth lookup bounds check\n",
    "            if 0 <= cx < width and 0 <= cy < height:\n",
    "                distance = depth_frame[cy, cx]\n",
    "\n",
    "                if not np.isnan(distance) and distance > 0:\n",
    "                    if distance < min_distance:\n",
    "                        min_distance = distance\n",
    "                        best_bbox = bbox\n",
    "                        best_center = [cx, cy]\n",
    "\n",
    "    return best_bbox is not None, min_distance, best_bbox, best_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_to_angle(px, py, width, height, hfov, vfov):\n",
    "\n",
    "    cx, cy = width / 2, height / 2\n",
    "\n",
    "    h_angle = ((px - cx) / cx) * (hfov / 2)\n",
    "    v_angle = ((py - cy) / cy) * (vfov / 2)\n",
    "\n",
    "    return h_angle, v_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-21 10:08:59 UTC][ZED][INFO] Logging level INFO\n",
      "[2025-11-21 10:08:59 UTC][ZED][INFO] Logging level INFO\n",
      "Camera error: CAMERA NOT DETECTED\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-21 10:08:59 UTC][ZED][INFO] Logging level INFO\n",
      "[2025-11-21 10:09:00 UTC][ZED][WARNING] CAMERA NOT DETECTED in sl::ERROR_CODE sl::Camera::open(sl::InitParameters)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from camera import Camera \n",
    "from springfollower import SpringFollower\n",
    "\n",
    "#create a camera object\n",
    "cam = Camera()\n",
    "cam.start() # start capturing the data\n",
    "\n",
    "#create follower\n",
    "follower = SpringFollower(speed=0.0, follow_distance=5.0, stopping_distance=2.0, v_max = 1.0, deadband=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "\n",
    "display_camera = True\n",
    "\n",
    "run_time = range(300)\n",
    "start_time = time.time()\n",
    "yolo_interval = 5\n",
    "\n",
    "\n",
    "latest_color_frame = None\n",
    "latest_depth_frame = None\n",
    "\n",
    "latest_results = None\n",
    "\n",
    "# =========== Main Loop ===========\n",
    "for i in run_time:\n",
    "    # get current frame\n",
    "    latest_color_frame, latest_depth_frame = cam.get_frame()\n",
    "\n",
    "    # detect humans\n",
    "    if run_time % yolo_interval == 0:\n",
    "        latest_results = model(latest_color_frame, classes=[0], verbose=False)\n",
    "    found, dist, bbox, center = detect_human_from_results(\n",
    "        latest_results, latest_depth_frame, cam.width, cam.height\n",
    "        )\n",
    "    \n",
    "    # calculate angle deviation from center\n",
    "    angle = pixel_to_angle(\n",
    "        center[0], center[1], cam.width, cam.height, cam.hfov, cam.vfov\n",
    "    )\n",
    "\n",
    "    if found:\n",
    "        follower.update(angle, dist)\n",
    "\n",
    "\n",
    "\n",
    "    # =========== Display images ===========\n",
    "    \n",
    "    if display_camera:\n",
    "        # Prepare depth colormap for display\n",
    "        depth_colormap = cv2.applyColorMap(\n",
    "            cv2.convertScaleAbs(latest_depth_frame, alpha=0.03), \n",
    "            cv2.COLORMAP_JET)\n",
    "        scale = 0.1\n",
    "        resized_color = cv2.resize(latest_color_frame, None, fx=scale, fy=scale, \n",
    "                                   interpolation=cv2.INTER_AREA)\n",
    "        resized_depth = cv2.resize(depth_colormap, None, fx=scale, fy=scale, \n",
    "                                   interpolation=cv2.INTER_AREA)\n",
    "        display_color.value = bgr8_to_jpeg(resized_color)\n",
    "        display_depth.value = bgr8_to_jpeg(resized_depth)\n",
    "\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Full model inference on 300 frames completed.\")\n",
    "print(f\"Elapsed Time: {elapsed_time} seconds\")\n",
    "\n",
    "control_frequency = len(run_time)/elapsed_time\n",
    "print(f\"Control frequency = \", control_frequency)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#follower.stop()\n",
    "#camera.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
