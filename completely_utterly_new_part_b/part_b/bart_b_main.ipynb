{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'motors'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmotors\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Create widgets for displaying images\u001b[39;00m\n\u001b[0;32m      8\u001b[0m display_color \u001b[38;5;241m=\u001b[39m widgets\u001b[38;5;241m.\u001b[39mImage(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjpeg\u001b[39m\u001b[38;5;124m'\u001b[39m, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m45\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'motors'"
     ]
    }
   ],
   "source": [
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "import cv2\n",
    "import motors\n",
    "\n",
    "# Create widgets for displaying images\n",
    "display_color = widgets.Image(format='jpeg', width='45%')\n",
    "display_depth = widgets.Image(format='jpeg', width='45%')\n",
    "layout = widgets.Layout(width='100%')\n",
    "\n",
    "sidebyside = widgets.HBox([display_color, display_depth], layout=layout)\n",
    "display(sidebyside)\n",
    "\n",
    "# Convert numpy array to jpeg coded data for displaying\n",
    "def bgr8_to_jpeg(value):\n",
    "    return bytes(cv2.imencode('.jpg', value)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# full model\n",
    "model = YOLO(\"yolo11l_half.engine\")\n",
    "\n",
    "# human only model\n",
    "# model = YOLO('best.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def detect_human_from_results(results, depth_frame, width, height):\n",
    "    min_distance = float('inf')\n",
    "    best_bbox = None\n",
    "    best_center = None\n",
    "\n",
    "    for result in results:\n",
    "        for i, bbox in enumerate(result.boxes.xyxy):\n",
    "            cx = int((bbox[0] + bbox[2]) / 2)\n",
    "            cy = int((bbox[1] + bbox[3]) / 2)\n",
    "\n",
    "            # Depth lookup bounds check\n",
    "            if 0 <= cx < width and 0 <= cy < height:\n",
    "                distance = depth_frame[cy, cx]\n",
    "\n",
    "                if not np.isnan(distance) and distance > 0:\n",
    "                    if distance < min_distance:\n",
    "                        min_distance = distance\n",
    "                        best_bbox = bbox\n",
    "                        best_center = [cx, cy]\n",
    "\n",
    "    return best_bbox is not None, min_distance, best_bbox, best_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_to_angle(px, py, width, height, hfov, vfov):\n",
    "\n",
    "    cx, cy = width / 2, height / 2\n",
    "\n",
    "    h_angle = ((px - cx) / cx) * (hfov / 2)\n",
    "    v_angle = ((py - cy) / cy) * (vfov / 2)\n",
    "\n",
    "    return h_angle, v_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import camera\n",
    "import springfollower\n",
    "\n",
    "#create a camera object\n",
    "cam = Camera()\n",
    "cam.start() # start capturing the data\n",
    "\n",
    "#create follower\n",
    "follower = SpringFollower(speed=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# =========== Main Loop ===========\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m run_time:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# get current frame\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     latest_color_frame, latest_depth_frame \u001b[38;5;241m=\u001b[39m \u001b[43mcam\u001b[49m\u001b[38;5;241m.\u001b[39mget_frame()\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# detect humans\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m run_time \u001b[38;5;241m%\u001b[39m yolo_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cam' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "\n",
    "display_camera = True\n",
    "\n",
    "run_time = range(300)\n",
    "start_time = time.time()\n",
    "yolo_interval = 5\n",
    "\n",
    "\n",
    "latest_color_frame = None\n",
    "latest_depth_frame = None\n",
    "\n",
    "latest_results = None\n",
    "\n",
    "# =========== Main Loop ===========\n",
    "for i in run_time:\n",
    "    # get current frame\n",
    "    latest_color_frame, latest_depth_frame = cam.get_frame()\n",
    "\n",
    "    # detect humans\n",
    "    if run_time % yolo_interval == 0:\n",
    "        latest_results = model(latest_color_frame, classes=[0], verbose=False)\n",
    "    found, dist, bbox, center = detect_human_from_results(\n",
    "        latest_results, latest_depth_frame, cam.width, cam.height\n",
    "        )\n",
    "    \n",
    "    # calculate angle deviation from center\n",
    "    angle = pixel_to_angle(\n",
    "        center[0], center[1], cam.width, cam.height, cam.hfov, cam.vfov\n",
    "    )\n",
    "\n",
    "    if found:\n",
    "        follower.update(angle, dist)\n",
    "\n",
    "\n",
    "\n",
    "    # =========== Display images ===========\n",
    "    \n",
    "    if display_camera:\n",
    "        # Prepare depth colormap for display\n",
    "        depth_colormap = cv2.applyColorMap(\n",
    "            cv2.convertScaleAbs(latest_depth_frame, alpha=0.03), \n",
    "            cv2.COLORMAP_JET)\n",
    "        scale = 0.1\n",
    "        resized_color = cv2.resize(latest_color_frame, None, fx=scale, fy=scale, \n",
    "                                   interpolation=cv2.INTER_AREA)\n",
    "        resized_depth = cv2.resize(depth_colormap, None, fx=scale, fy=scale, \n",
    "                                   interpolation=cv2.INTER_AREA)\n",
    "        display_color.value = bgr8_to_jpeg(resized_color)\n",
    "        display_depth.value = bgr8_to_jpeg(resized_depth)\n",
    "\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Full model inference on 300 frames completed.\")\n",
    "print(f\"Elapsed Time: {elapsed_time} seconds\")\n",
    "\n",
    "control_frequency = len(run_time)/elapsed_time\n",
    "print(f\"Control frequency = \", control_frequency)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#follower.stop()\n",
    "#camera.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
